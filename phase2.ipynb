{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9784a9ed-b5e2-47fb-b3a4-068472829833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2db8f5ca-0b34-462b-a763-d3d6e4f8f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"heart_attack_prediction_dataset.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c90f7410-9911-4058-aaae-93f1e3474fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(df, column):\n",
    "    # Implement your accuracy calculation logic here\n",
    "    # This can involve comparing data to a ground truth or expected values\n",
    "    return 100  # Placeholder value, replace with actual accuracy calculation\n",
    "\n",
    "def calculate_validity(df, column):\n",
    "    # Implement your validity calculation logic here\n",
    "    # This can involve checking if data conforms to defined types or formats\n",
    "    valid_values = df[column].apply(lambda x: is_valid(x))  # Implement is_valid function\n",
    "    validity_percentage = (valid_values.sum() / len(df)) * 100\n",
    "    return validity_percentage\n",
    "\n",
    "def is_valid(value):\n",
    "    # Implement your specific validity check logic here\n",
    "    # Example: Check if the value is within a certain range or adheres to a specific format\n",
    "    return True  # Placeholder value, replace with actual validity check\n",
    "\n",
    "def calculate_correctness(df, column):\n",
    "    # Implement your correctness calculation logic here\n",
    "    # This can involve comparing data to a known set of correct values\n",
    "    return 100  # Placeholder value, replace with actual correctness calculation\n",
    "\n",
    "def calculate_consistency(df, column):\n",
    "    # Implement your consistency calculation logic here\n",
    "    # This can involve checking if data is consistent across records or features\n",
    "    consistency_values = df[column].duplicated().sum()\n",
    "    consistency_percentage = ((len(df) - consistency_values) / len(df)) * 100\n",
    "    return consistency_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "061a0318-9e02-45a1-bc1f-d6802e508fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Number of Null Values</th>\n",
       "      <th>Completeness (%)</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Validity (%)</th>\n",
       "      <th>Correctness (%)</th>\n",
       "      <th>Consistency (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patient ID</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.833048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.022823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cholesterol</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>3.206664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blood Pressure</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>44.676481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Heart Rate</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.810225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.022823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Family History</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.022823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Smoking</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.022823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Obesity</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.022823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alcohol Consumption</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.022823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Exercise Hours Per Week</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Diet</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.034235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Previous Heart Problems</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.022823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Medication Use</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.022823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Stress Level</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.114116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sedentary Hours Per Day</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Income</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>98.311081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BMI</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Triglycerides</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>8.798357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Physical Activity Days Per Week</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.091293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sleep Hours Per Day</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.079881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Country</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.228232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Continent</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.068470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Hemisphere</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.022823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Heart Attack Risk</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.022823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Feature Number of Null Values  Completeness (%)  \\\n",
       "0                        Patient ID                     0             100.0   \n",
       "1                               Age                     0             100.0   \n",
       "2                               Sex                     0             100.0   \n",
       "3                       Cholesterol                     0             100.0   \n",
       "4                    Blood Pressure                     0             100.0   \n",
       "5                        Heart Rate                     0             100.0   \n",
       "6                          Diabetes                     0             100.0   \n",
       "7                    Family History                     0             100.0   \n",
       "8                           Smoking                     0             100.0   \n",
       "9                           Obesity                     0             100.0   \n",
       "10              Alcohol Consumption                     0             100.0   \n",
       "11          Exercise Hours Per Week                     0             100.0   \n",
       "12                             Diet                     0             100.0   \n",
       "13          Previous Heart Problems                     0             100.0   \n",
       "14                   Medication Use                     0             100.0   \n",
       "15                     Stress Level                     0             100.0   \n",
       "16          Sedentary Hours Per Day                     0             100.0   \n",
       "17                           Income                     0             100.0   \n",
       "18                              BMI                     0             100.0   \n",
       "19                    Triglycerides                     0             100.0   \n",
       "20  Physical Activity Days Per Week                     0             100.0   \n",
       "21              Sleep Hours Per Day                     0             100.0   \n",
       "22                          Country                     0             100.0   \n",
       "23                        Continent                     0             100.0   \n",
       "24                       Hemisphere                     0             100.0   \n",
       "25                Heart Attack Risk                     0             100.0   \n",
       "\n",
       "   Accuracy (%)  Validity (%) Correctness (%)  Consistency (%)  \n",
       "0           100         100.0             100       100.000000  \n",
       "1           100         100.0             100         0.833048  \n",
       "2           100         100.0             100         0.022823  \n",
       "3           100         100.0             100         3.206664  \n",
       "4           100         100.0             100        44.676481  \n",
       "5           100         100.0             100         0.810225  \n",
       "6           100         100.0             100         0.022823  \n",
       "7           100         100.0             100         0.022823  \n",
       "8           100         100.0             100         0.022823  \n",
       "9           100         100.0             100         0.022823  \n",
       "10          100         100.0             100         0.022823  \n",
       "11          100         100.0             100       100.000000  \n",
       "12          100         100.0             100         0.034235  \n",
       "13          100         100.0             100         0.022823  \n",
       "14          100         100.0             100         0.022823  \n",
       "15          100         100.0             100         0.114116  \n",
       "16          100         100.0             100       100.000000  \n",
       "17          100         100.0             100        98.311081  \n",
       "18          100         100.0             100       100.000000  \n",
       "19          100         100.0             100         8.798357  \n",
       "20          100         100.0             100         0.091293  \n",
       "21          100         100.0             100         0.079881  \n",
       "22          100         100.0             100         0.228232  \n",
       "23          100         100.0             100         0.068470  \n",
       "24          100         100.0             100         0.022823  \n",
       "25          100         100.0             100         0.022823  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Create a DataFrame to store quality assessments\n",
    "quality_df = pd.DataFrame(columns=['Feature', 'Number of Null Values', 'Completeness (%)', 'Accuracy (%)', 'Validity (%)', 'Correctness (%)', 'Consistency (%)'])\n",
    "\n",
    "# Iterate through each column in the dataset\n",
    "for column in df.columns:\n",
    "    num_null_values = df[column].isnull().sum()\n",
    "    completeness = 100 - (num_null_values / len(df)) * 100\n",
    "\n",
    "    # Assess accuracy, validity, correctness, and consistency as needed\n",
    "    accuracy = calculate_accuracy(df, column)  # Implement your accuracy calculation function\n",
    "    validity = calculate_validity(df, column)  # Implement your validity calculation function\n",
    "    correctness = calculate_correctness(df, column)  # Implement your correctness calculation function\n",
    "    consistency = calculate_consistency(df, column)  # Implement your consistency calculation function\n",
    "\n",
    "    prepare_df = {\n",
    "            'Feature': [column],\n",
    "            'Number of Null Values': [num_null_values],\n",
    "            'Completeness (%)': [completeness],\n",
    "            'Accuracy (%)': [accuracy],\n",
    "            'Validity (%)': [validity],\n",
    "            'Correctness (%)': [correctness],\n",
    "            'Consistency (%)': [consistency]\n",
    "        }\n",
    "\n",
    "    # Append results to the quality DataFrame\n",
    "    quality_df = pd.concat([quality_df, pd.DataFrame(prepare_df)], ignore_index=True)\n",
    "\n",
    "# Display the resulting quality assessments\n",
    "quality_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c28d3-a066-499d-9cbf-34b6045782f4",
   "metadata": {},
   "source": [
    "# Improve quality\n",
    "\n",
    "Improving data quality involves a combination of data cleansing, validation, and enhancement techniques. Here are some solutions to enhance the quality of your data:\n",
    "\n",
    "Handling Missing Values:\n",
    "\n",
    "Identify columns with missing values and decide on an appropriate strategy (imputation, removal, etc.).\n",
    "For numerical features, consider imputing missing values with the mean, median, or a regression-based approach.\n",
    "For categorical features, impute missing values with the mode or use a separate category.\n",
    "Outlier Detection and Treatment:\n",
    "\n",
    "Identify and analyze outliers using statistical methods like the interquartile range (IQR) or Z-scores.\n",
    "Decide whether to remove outliers or apply appropriate transformations to mitigate their impact.\n",
    "Data Type and Format Validation:\n",
    "\n",
    "Ensure that data types and formats are consistent with expectations.\n",
    "Validate numerical columns to ensure they contain valid numeric values.\n",
    "Validate categorical columns to ensure they contain expected categories.\n",
    "Cross-Column Consistency Checks:\n",
    "\n",
    "Check for consistency between related columns. For example, ensure that the 'Age' column aligns with the 'Birthdate' column.\n",
    "Identify and rectify discrepancies between columns that should contain similar information.\n",
    "Standardize and Normalize Data:\n",
    "\n",
    "Standardize units and formats for numerical data (e.g., convert all weights to kilograms).\n",
    "Normalize data when necessary, especially for machine learning models that are sensitive to the scale of features.\n",
    "Addressing Duplicate Records:\n",
    "\n",
    "Identify and remove duplicate records based on unique identifiers.\n",
    "Implement checks to prevent the creation of duplicate records in the future.\n",
    "Implement Data Validation Rules:\n",
    "\n",
    "Define and enforce data validation rules specific to each feature.\n",
    "For example, set range constraints on numerical features, validate date formats, and enforce unique constraints where applicable.\n",
    "Documentation and Metadata:\n",
    "\n",
    "Maintain comprehensive documentation for the dataset, including data dictionaries and metadata.\n",
    "Clearly define the meaning and expected values for each feature.\n",
    "Data Profiling and Exploration:\n",
    "\n",
    "Use data profiling techniques to explore and understand the distribution of values in each column.\n",
    "Identify patterns, anomalies, and potential issues that need attention.\n",
    "Automated Data Quality Checks:\n",
    "\n",
    "Implement automated data quality checks as part of your data processing pipeline.\n",
    "Regularly monitor and alert on data quality issues to facilitate timely intervention.\n",
    "User Training and Awareness:\n",
    "\n",
    "Train users who interact with the data on best practices for data entry and maintenance.\n",
    "Foster a culture of data quality within the organization.\n",
    "Continuous Monitoring and Improvement:\n",
    "\n",
    "Set up regular data quality monitoring processes to detect issues early.\n",
    "Establish a feedback loop for continuous improvement based on data quality insights.\n",
    "Remember that data quality is an ongoing process, and regular monitoring and improvement efforts are crucial to maintaining high-quality data. Tailor these solutions to the specific characteristics and requirements of your dataset and use case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
